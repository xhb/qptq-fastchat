{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## xiier虚拟人后端接口, 使用vicuna-13b作为大模型支持openai的api, 添加中文asr接口, 中文TTS接口, 中文sentiment分析接口, 方便单机部署虚拟人项目"
      ],
      "metadata": {
        "id": "nRp2bIG0Ii-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 播放一个音频,让colab长时间运行不自动断开连接 { display-mode: \"form\" }\n",
        "\n",
        "#@markdown 运行后让音频一直播放:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "D37J_WsQyssB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 检查设备环境, 并且下载接口代码"
      ],
      "metadata": {
        "id": "w_YfXt9UI4Ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "id": "KLD7I-ZmM2fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 下载项目代码安装全部环境依赖"
      ],
      "metadata": {
        "id": "2lv8EzfYAJRO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o_PkmcuIVeg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/xhb/xiier-fastchat.git\n",
        "%cd /content/xiier-fastchat\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/xiier-fastchat/fastchat/vits_tts_zh/\n",
        "!pip install -r ./vits/requirements.txt\n"
      ],
      "metadata": {
        "id": "Jkk5Hu_F2qD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/xiier-fastchat/fastchat/vits_tts_zh/vits/monotonic_align\n",
        "!mkdir monotonic_align\n",
        "!python setup.py build_ext --inplace\n",
        "%cd /content/xiier-fastchat"
      ],
      "metadata": {
        "id": "zM8SaWu_3FoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 安装稳定版本的llama Gptq模型支持库"
      ],
      "metadata": {
        "id": "4I-Fk0Jnb5dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir repositories\n",
        "%cd repositories\n",
        "!git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "%cd GPTQ-for-LLaMa\n",
        "!python setup_cuda.py install\n",
        "%cd ../.."
      ],
      "metadata": {
        "id": "y9hVyXRNP464"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 下载 vicuna-13GPTQ模型, 中文语音识别 asr_zh 模型, 中文语音生成 vits_zh 模型, 中文情感色彩分析模型"
      ],
      "metadata": {
        "id": "T4bbKKcUJ2SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python download-model.py anon8231489123/vicuna-13b-GPTQ-4bit-128g"
      ],
      "metadata": {
        "id": "ljc1JnLzQx9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download-model.py xiier/asr_zh"
      ],
      "metadata": {
        "id": "hitYKJhWH_sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download-model.py xiier/vits_zh"
      ],
      "metadata": {
        "id": "kGOmx2yp2jIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download-model.py xiier/sentiment_cls"
      ],
      "metadata": {
        "id": "8MK_-tKxHloY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install ffmpeg --fix-missing && ffmpeg -version"
      ],
      "metadata": {
        "id": "xbWCKcWgKC8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 构建openai官方接口, 中文语音识别接口, 中文文字朗读TTS接口, 中文情感色彩分析接口"
      ],
      "metadata": {
        "id": "by73OmyOdFHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install screen"
      ],
      "metadata": {
        "id": "AUh0bNMzVj0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!screen -S controller -dm python -m fastchat.serve.controller --host \"127.0.0.1\" --port 21001"
      ],
      "metadata": {
        "id": "oFLTkXN4Vofp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在这一行执行之后等待大概30s,等待gpu的显存加载模型完成, 再启动web服务"
      ],
      "metadata": {
        "id": "1XRx20jYwZM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!screen -S controller -dm python -m fastchat.serve.model_worker --model-path \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\" --model-name \"text-embedding-ada-002\" --gptq-wbits 4 --gptq-groupsize 128 --host \"127.0.0.1\" --port 21002 --worker-address \"http://127.0.0.1:21002\" --controller-address \"http://127.0.0.1:21001\""
      ],
      "metadata": {
        "id": "4Gar7sqwVu1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用 ngrok 把本地的http服务代理到公共url"
      ],
      "metadata": {
        "id": "CkJyRAGAdWsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "WOc-atZ8GICS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "port = 5555\n",
        "ngrok.set_auth_token(\"2QRC3hph4qKZrV5aSXPHylX5hzF_4iinXrMr6VM4tJir9iGEK\")\n",
        "public_url = ngrok.connect(port).public_url\n",
        "\n",
        "print(\"baseUrl: \\\"{}\\\"\".format(public_url))\n"
      ],
      "metadata": {
        "id": "nRCOgMSfdfxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m fastchat.serve.openai_api_server --controller-address \"http://127.0.0.1:21001\" --host \"0.0.0.0\" --port 5555"
      ],
      "metadata": {
        "id": "Y0un6fclWRc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### debug: ***启动调试终端开始调试 (调试可用)***"
      ],
      "metadata": {
        "id": "9OpqbtcdsZvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "S9OcxAwJkVaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "R8SVjckAwTfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}